[core]
dags_folder = /opt/airflow/dags
plugins_folder = /opt/airflow/plugins
default_timezone = utc
executor = SequentialExecutor
parallelism = 32
max_active_tasks_per_dag = 16
dags_are_paused_at_creation = True
max_active_runs_per_dag = 16
max_consecutive_failed_dag_runs_per_dag = 0
load_examples = False
donot_pickle = True
default_task_retries = 0
default_task_retry_delay = 300
max_task_retry_delay = 86400
default_task_weight_rule = downstream
min_serialized_dag_update_interval = 30
compress_serialized_dags = False
xcom_backend = airflow.models.xcom.BaseXCom
lazy_load_plugins = True
lazy_discover_providers = True
hide_sensitive_var_conn_fields = True
default_pool_task_slot_count = 128
killed_task_cleanup_time = 60
dag_run_conf_overrides_params = True
dag_discovery_safe_mode = True
dag_ignore_file_syntax = regexp
check_slas = True
max_templated_field_length = 4096

[database]
sql_alchemy_conn = sqlite:////opt/airflow/airflow.db
sql_alchemy_pool_enabled = True
sql_alchemy_pool_size = 5
sql_alchemy_max_overflow = 10
sql_alchemy_pool_recycle = 1800
sql_alchemy_pool_pre_ping = True
max_db_retries = 3

[logging]
base_log_folder = /opt/airflow/logs
remote_logging = False
logging_level = INFO
fab_logging_level = WARNING
log_format = [%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s
simple_log_format = %(asctime)s %(levelname)s - %(message)s
task_log_reader = task
file_task_handler_new_folder_permissions = 0o775
file_task_handler_new_file_permissions = 0o664
enable_task_context_logger = True

[metrics]
statsd_on = False

[secrets]
use_cache = False
cache_ttl_seconds = 900

[cli]
api_client = airflow.api.client.local_client
endpoint_url = http://localhost:8080

[debug]
fail_fast = False

[api]
enable_experimental_api = False
auth_backends = airflow.api.auth.backend.session

[operators]
default_owner = airflow
default_deferrable = False
default_cpus = 1
default_ram = 512
default_disk = 512
default_gpus = 0
default_queue = default
allow_illegal_arguments = False

[webserver]
base_url = http://localhost:8080
web_server_host = 0.0.0.0
web_server_port = 8080
session_backend = database
web_server_master_timeout = 120
web_server_worker_timeout = 120
workers = 4
worker_class = sync
default_dag_run_display_number = 25
cookie_samesite = Lax

[email]
email_backend = airflow.utils.email.send_email_smtp
email_conn_id = smtp_default
default_email_on_retry = True
default_email_on_failure = True

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_port = 25
smtp_mail_from = airflow@example.com
smtp_timeout = 30

[scheduler]
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 5
num_runs = -1
scheduler_idle_sleep_time = 1
min_file_process_interval = 30
parsing_cleanup_interval = 60
stale_dag_threshold = 50
dag_dir_list_interval = 300
print_stats_interval = 30
pool_metrics_interval = 5.0
scheduler_health_check_threshold = 30
catchup_by_default = True
ignore_first_depends_on_past_by_default = True
max_tis_per_query = 16
use_row_level_locking = True
max_dagruns_to_create_per_loop = 10
max_dagruns_per_loop_to_schedule = 20
schedule_after_task_execution = True
parsing_pre_import_modules = True
parsing_processes = 2
file_parsing_sort_mode = modified_time

[triggerer]
default_capacity = 1000
job_heartbeat_sec = 5
triggerer_health_check_threshold = 30

[kerberos]
ccache = /tmp/airflow_krb5_ccache
principal = airflow
reinit_frequency = 3600
kinit_path = kinit
keytab = airflow.keytab
forwardable = True

[sensors]
default_timeout = 604800

[aws]
cloudwatch_task_handler_json_serializer = airflow.providers.amazon.aws.log.cloudwatch_task_handler.json_serialize_legacy

[aws_batch_executor]
conn_id = aws_default
max_submit_job_attempts = 3
check_health_on_startup = True

[aws_ecs_executor]
conn_id = aws_default
assign_public_ip = False
platform_version = LATEST
max_run_task_attempts = 3
check_health_on_startup = True

[celery]
broker_url = redis://redis:6379/0
result_backend_sqlalchemy_engine_options = 
flower_host = 0.0.0.0
flower_port = 5555
worker_prefetch_multiplier = 1
task_acks_late = True
task_track_started = True
task_publish_max_retries = 3
worker_enable_remote_control = True
pool = prefork

[local_kubernetes_executor]
kubernetes_queue = kubernetes

[kubernetes_executor]
namespace = default
delete_worker_pods = True
delete_worker_pods_on_failure = False
worker_pod_pending_fatal_container_state_reasons = CreateContainerConfigError,ErrImagePull,CreateContainerError,ImageInspectError, InvalidImageName
worker_pods_creation_batch_size = 1
enable_tcp_keepalive = True

[common.io]
xcom_objectstorage_threshold = -1

[elasticsearch]
log_id_template = {dag_id}-{task_id}-{run_id}-{map_index}-{try_number}
write_stdout = False

[fab]
auth_rate_limited = True
auth_rate_limit = 5 per 40 second
update_fab_perms = True

[imap]
[azure_remote_logging]
remote_wasb_log_container = airflow-logs

[openlineage]
disabled = False
disable_source_code = False
dag_state_change_process_pool_size = 1
execution_timeout = 10